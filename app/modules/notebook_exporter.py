"""
DataPilot AI — Reproducible Notebook Exporter
Generates Jupyter notebooks (.ipynb) with all analysis steps preserved.
"""

import json
import datetime
import pandas as pd
import numpy as np
from typing import List, Dict, Optional


def _make_cell(cell_type: str, source: str, outputs=None) -> dict:
    """Create a Jupyter notebook cell dict."""
    cell = {
        "cell_type": cell_type,
        "metadata": {},
        "source": source,
    }
    if cell_type == "code":
        cell["outputs"] = outputs or []
        cell["execution_count"] = None
    return cell


def generate_notebook(
    file_name: str,
    df: pd.DataFrame,
    cleaning_steps: List[str] = None,
    ml_config: Optional[Dict] = None,
    trust_score: Optional[Dict] = None,
) -> str:
    """
    Generate a complete Jupyter notebook as a JSON string.
    Includes: setup, data loading, cleaning, EDA, ML training.
    """

    cells = []
    ts = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")

    # Limit column explosion for very wide datasets
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()[:30]
    cat_cols = df.select_dtypes(include="object").columns.tolist()[:30]

    # ─────────────────────────────────────────────────────────────
    # 1. Title
    # ─────────────────────────────────────────────────────────────
    cells.append(_make_cell("markdown", f"""# DataPilot AI — Generated Analysis Notebook
**Dataset:** `{file_name}`  
**Generated:** {ts}  
**Rows:** {len(df):,} | **Columns:** {len(df.columns)}  

> Auto-generated by DataPilot AI.
"""))

    # ─────────────────────────────────────────────────────────────
    # 2. Setup
    # ─────────────────────────────────────────────────────────────
    cells.append(_make_cell("markdown", "## 1. Setup & Imports"))

    cells.append(_make_cell("code", """import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import warnings
warnings.filterwarnings('ignore')

np.random.seed(42)

plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("Environment ready ✅")
"""))

    # ─────────────────────────────────────────────────────────────
    # 3. Data Loading
    # ─────────────────────────────────────────────────────────────
    cells.append(_make_cell("markdown", "## 2. Data Loading"))

    ext = file_name.split(".")[-1].lower() if "." in file_name else "csv"
    read_fn = {
        "csv": f"pd.read_csv('{file_name}')",
        "xlsx": f"pd.read_excel('{file_name}')",
        "json": f"pd.read_json('{file_name}')",
        "parquet": f"pd.read_parquet('{file_name}')",
    }.get(ext, f"pd.read_csv('{file_name}')")

    cells.append(_make_cell("code", f"""df = {read_fn}

print(f"Shape: {{df.shape[0]:,}} rows × {{df.shape[1]}} columns")
df.head()
"""))

    cells.append(_make_cell("code", """print(df.info())
print("\\nMissing values:")
print(df.isna().sum()[df.isna().sum() > 0])
"""))

    # ─────────────────────────────────────────────────────────────
    # 4. Trust Score
    # ─────────────────────────────────────────────────────────────
    if trust_score:
        score = float(trust_score.get("overall", 0))
        dimensions = {
            k: float(v) for k, v in trust_score.get("dimensions", {}).items()
        }

        cells.append(_make_cell("markdown", f"""## 3. Dataset Quality Assessment

**Trust Score: {score:.0%}**
"""))

        cells.append(_make_cell("code", f"""trust_dimensions = {dimensions}

import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(8, 4))
bars = ax.barh(list(trust_dimensions.keys()),
               list(trust_dimensions.values()))

ax.set_xlim(0, 1)
ax.set_xlabel("Score")
ax.set_title("Dataset Trust Score")

for bar, val in zip(bars, trust_dimensions.values()):
    ax.text(val + 0.01, bar.get_y() + bar.get_height()/2,
            f"{{val:.0%}}", va="center")

plt.tight_layout()
plt.show()
"""))

    # ─────────────────────────────────────────────────────────────
    # 5. EDA
    # ─────────────────────────────────────────────────────────────
    cells.append(_make_cell("markdown", "## 4. Exploratory Data Analysis"))

    cells.append(_make_cell("code", """df.describe(include='all').round(3)"""))

    # Correlation
    if len(numeric_cols) > 1:
        cells.append(_make_cell("code", f"""numeric_cols = {numeric_cols}
corr = df[numeric_cols].corr()

import plotly.express as px
fig = px.imshow(corr,
                text_auto='.2f',
                aspect='auto',
                title="Correlation Heatmap")
fig.show()
"""))
    else:
        cells.append(_make_cell("code", """print("Not enough numeric columns for correlation heatmap.")"""))

    # Distribution plots (safe version)
    if numeric_cols:
        cells.append(_make_cell("code", f"""num_cols = {numeric_cols}[:6]
n = len(num_cols)

if n > 0:
    rows = int(np.ceil(n / 2))
    fig, axes = plt.subplots(rows, 2, figsize=(14, 4 * rows))
    axes = np.array(axes).reshape(-1)

    for i, col in enumerate(num_cols):
        df[col].dropna().hist(ax=axes[i], bins=30)
        axes[i].set_title(f"Distribution: {{col}}")

    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()
"""))

    # Categorical plots
    if cat_cols:
        cells.append(_make_cell("code", f"""cat_cols = {cat_cols}[:4]

for col in cat_cols:
    vc = df[col].value_counts().head(15)
    fig = px.bar(x=vc.index,
                 y=vc.values,
                 title=f"Top Values: {{col}}")
    fig.update_layout(xaxis_title=col,
                      yaxis_title="Count")
    fig.show()
"""))

    # ─────────────────────────────────────────────────────────────
    # 6. Cleaning
    # ─────────────────────────────────────────────────────────────
    cells.append(_make_cell("markdown", "## 5. Data Cleaning"))

    cleaning_code = "df_clean = df.copy()\n\n"

    if cleaning_steps:
        cleaning_code += "# Applied cleaning steps:\n"
        for step in cleaning_steps:
            cleaning_code += f"# {step}\n"
        cleaning_code += "\n"

    cleaning_code += """# Fill numeric NaNs
for col in df_clean.select_dtypes(include='number').columns:
    df_clean[col] = df_clean[col].fillna(df_clean[col].median())

# Fill categorical NaNs
for col in df_clean.select_dtypes(include='object').columns:
    mode = df_clean[col].mode()
    df_clean[col] = df_clean[col].fillna(mode.iloc[0] if not mode.empty else "Unknown")

df_clean = df_clean.drop_duplicates()

print(f"Cleaned shape: {df_clean.shape[0]:,} rows × {df_clean.shape[1]} columns")
"""

    cells.append(_make_cell("code", cleaning_code))

    # ─────────────────────────────────────────────────────────────
    # 7. Machine Learning
    # ─────────────────────────────────────────────────────────────
    if ml_config and ml_config.get("target_col"):
        target = ml_config["target_col"]

        cells.append(_make_cell("markdown", f"""## 6. Machine Learning

**Target:** `{target}`
"""))

        cells.append(_make_cell("code", f"""from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, classification_report, r2_score

target_col = "{target}"

df_ml = df_clean.copy()
df_ml = df_ml.dropna(subset=[target_col])

feature_cols = [c for c in df_ml.columns if c != target_col]

original_y = df_ml[target_col]
is_classification = (
    original_y.dtype == "object" or
    original_y.nunique() <= 20
)

# Encode features
for col in feature_cols:
    if df_ml[col].dtype == "object":
        df_ml[col] = LabelEncoder().fit_transform(df_ml[col].astype(str))

# Encode target if classification
if is_classification and df_ml[target_col].dtype == "object":
    df_ml[target_col] = LabelEncoder().fit_transform(df_ml[target_col].astype(str))

# Impute
imputer = SimpleImputer(strategy="median")
X = pd.DataFrame(imputer.fit_transform(df_ml[feature_cols]),
                 columns=feature_cols)
y = df_ml[target_col]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model = (
    RandomForestClassifier(random_state=42)
    if is_classification
    else RandomForestRegressor(random_state=42)
)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

if is_classification:
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print(classification_report(y_test, y_pred))
else:
    print("R² Score:", r2_score(y_test, y_pred))

# Feature importance
import plotly.express as px
fi = pd.Series(model.feature_importances_,
               index=feature_cols).sort_values(ascending=False).head(15)

fig = px.bar(x=fi.values,
             y=fi.index,
             orientation="h",
             title="Feature Importance")
fig.update_layout(yaxis=dict(autorange="reversed"))
fig.show()
"""))

    # ─────────────────────────────────────────────────────────────
    # 8. Export
    # ─────────────────────────────────────────────────────────────
    cells.append(_make_cell("markdown", "## 7. Export Results"))

    cells.append(_make_cell("code", """df_clean.to_csv("datapilot_cleaned_data.csv", index=False)
df_clean.describe().to_excel("datapilot_stats_summary.xlsx")

print("Exports completed ✅")
"""))

    # ─────────────────────────────────────────────────────────────
    # Build Notebook JSON
    # ─────────────────────────────────────────────────────────────
    notebook = {
        "nbformat": 4,
        "nbformat_minor": 5,
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3",
            },
            "language_info": {
                "name": "python",
                "version": "3.10.0",
            },
            "datapilot": {
                "generated": ts,
                "source_file": file_name,
                "version": "3.0",
            },
        },
        "cells": cells,
    }

    return json.dumps(notebook, indent=2, ensure_ascii=False) 


# -------------------------------------------------------------------------------------------------------
# """
# DataPilot AI — Reproducible Notebook Exporter
# Generates Jupyter notebooks (.ipynb) with all analysis steps preserved.
# """

# import json
# import datetime
# import pandas as pd
# import numpy as np
# from typing import List, Dict, Optional


# def _make_cell(cell_type: str, source: str, outputs=None) -> dict:
#     """Create a Jupyter notebook cell dict."""
#     cell = {
#         "cell_type": cell_type,
#         "metadata": {},
#         "source": source,
#     }
#     if cell_type == "code":
#         cell["outputs"] = outputs or []
#         cell["execution_count"] = None
#     return cell


# def generate_notebook(
#     file_name: str,
#     df: pd.DataFrame,
#     cleaning_steps: List[str] = None,
#     ml_config: Optional[Dict] = None,
#     trust_score: Optional[Dict] = None,
# ) -> str:
#     """
#     Generate a complete Jupyter notebook as a JSON string.
#     Includes: setup, data loading, cleaning, EDA, ML training.
#     """
#     cells = []
#     ts = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
#     numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
#     cat_cols = df.select_dtypes(include="object").columns.tolist()

#     # ── Title cell ────────────────────────────────────────────────────────────
#     cells.append(_make_cell("markdown", f"""# DataPilot AI — Generated Analysis Notebook
# **Dataset:** `{file_name}`  
# **Generated:** {ts}  
# **Rows:** {len(df):,} | **Columns:** {len(df.columns)}  

# > This notebook was auto-generated by [DataPilot AI](https://github.com/datapilot-ai). 
# > All analysis steps from your session have been reproduced here."""))

#     # ── Section 1: Setup ──────────────────────────────────────────────────────
#     cells.append(_make_cell("markdown", "## 1. Setup & Imports"))
#     cells.append(_make_cell("code", """import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# import plotly.express as px
# import plotly.graph_objects as go
# from scipy import stats
# import warnings
# warnings.filterwarnings('ignore')

# # Style
# plt.style.use('seaborn-v0_8-darkgrid')
# sns.set_palette("husl")
# print("✅ Libraries imported successfully")"""))

#     # ── Section 2: Data Loading ───────────────────────────────────────────────
#     cells.append(_make_cell("markdown", "## 2. Data Loading"))
#     ext = file_name.split(".")[-1].lower() if "." in file_name else "csv"
#     read_fn = {
#         "csv": f"pd.read_csv('{file_name}')",
#         "xlsx": f"pd.read_excel('{file_name}')",
#         "json": f"pd.read_json('{file_name}')",
#         "parquet": f"pd.read_parquet('{file_name}')",
#     }.get(ext, f"pd.read_csv('{file_name}')")

#     cells.append(_make_cell("code", f"""# Load your dataset (place the file in the same directory as this notebook)
# df = {read_fn}

# print(f"Shape: {{df.shape[0]:,}} rows × {{df.shape[1]}} columns")
# df.head()"""))

#     cells.append(_make_cell("code", """# Basic info
# print(df.info())
# print("\\n--- Missing Values ---")
# print(df.isna().sum()[df.isna().sum() > 0])"""))

#     # ── Section 3: Trust Score ────────────────────────────────────────────────
#     if trust_score:
#         score = trust_score.get("overall", 0)
#         cells.append(_make_cell("markdown", f"## 3. Dataset Quality Assessment\n\n**Trust Score: {score:.0%}** — {trust_score.get('label', '')}"))
#         cells.append(_make_cell("code", f"""# Dataset Trust Score components
# trust_dimensions = {json.dumps(trust_score.get('dimensions', {}), default=float)}

# fig, ax = plt.subplots(figsize=(8, 4))
# bars = ax.barh(list(trust_dimensions.keys()), list(trust_dimensions.values()), 
#                color=['#10b981' if v > 0.8 else '#f59e0b' if v > 0.6 else '#ef4444' 
#                       for v in trust_dimensions.values()])
# ax.set_xlim(0, 1)
# ax.set_xlabel('Score')
# ax.set_title(f'Dataset Trust Score: {score:.0%}', fontsize=14, fontweight='bold')
# for bar, val in zip(bars, trust_dimensions.values()):
#     ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{{val:.0%}}', va='center')
# plt.tight_layout()
# plt.show()"""))

#     # ── Section 4: Exploratory Analysis ──────────────────────────────────────
#     cells.append(_make_cell("markdown", "## 4. Exploratory Data Analysis"))
#     cells.append(_make_cell("code", """# Descriptive statistics
# df.describe(include='all').round(3)"""))

#     if len(numeric_cols) >= 2:
#         cells.append(_make_cell("code", f"""# Correlation heatmap
# numeric_cols = {numeric_cols}
# corr_matrix = df[numeric_cols].corr()

# fig = px.imshow(corr_matrix, 
#                 title='Correlation Heatmap',
#                 color_continuous_scale='RdBu_r',
#                 aspect='auto',
#                 text_auto='.2f')
# fig.update_layout(height=500)
# fig.show()"""))

#     if numeric_cols:
#         cells.append(_make_cell("code", f"""# Distribution plots for numeric features
# fig, axes = plt.subplots(nrows=min(3, len({numeric_cols})), ncols=2, figsize=(14, 3*min(3, len({numeric_cols}))))
# axes = axes.flatten() if len({numeric_cols}) > 1 else [axes]

# for i, col in enumerate({numeric_cols}[:6]):
#     try:
#         df[col].dropna().hist(ax=axes[i], bins=30, edgecolor='black', alpha=0.7)
#         axes[i].set_title(f'Distribution: {{col}}')
#     except: pass

# plt.tight_layout()
# plt.show()"""))

#     if cat_cols:
#         cells.append(_make_cell("code", f"""# Categorical value counts
# cat_cols = {cat_cols}
# for col in cat_cols[:4]:
#     vc = df[col].value_counts().head(15)
#     fig = px.bar(x=vc.index, y=vc.values, title=f'Top Values: {{col}}',
#                  labels={{'x': col, 'y': 'Count'}})
#     fig.show()"""))

#     # ── Section 5: Cleaning Steps ─────────────────────────────────────────────
#     cells.append(_make_cell("markdown", "## 5. Data Cleaning"))
#     cleaning_code = "df_clean = df.copy()\n\n"
#     if cleaning_steps:
#         cleaning_code += "# Applied cleaning steps from DataPilot AI session:\n"
#         for step in cleaning_steps:
#             cleaning_code += f"# {step}\n"
#         cleaning_code += "\n"

#     cleaning_code += """# Handle missing values (customize as needed)
# for col in df_clean.select_dtypes(include='number').columns:
#     df_clean[col] = df_clean[col].fillna(df_clean[col].median())

# for col in df_clean.select_dtypes(include='object').columns:
#     df_clean[col] = df_clean[col].fillna(df_clean[col].mode().iloc[0] if not df_clean[col].mode().empty else 'Unknown')

# # Remove duplicates
# df_clean = df_clean.drop_duplicates()
# print(f"Cleaned shape: {df_clean.shape[0]:,} rows × {df_clean.shape[1]} columns")"""

#     cells.append(_make_cell("code", cleaning_code))

#     # ── Section 6: ML Training ────────────────────────────────────────────────
#     if ml_config and ml_config.get("target_col"):
#         target = ml_config["target_col"]
#         algo = ml_config.get("algorithm", "Random Forest")
#         cells.append(_make_cell("markdown", f"## 6. Machine Learning\n\n**Target:** `{target}` | **Algorithm:** {algo}"))
#         cells.append(_make_cell("code", f"""from sklearn.model_selection import train_test_split, cross_val_score
# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
# from sklearn.preprocessing import LabelEncoder
# from sklearn.impute import SimpleImputer
# from sklearn.metrics import accuracy_score, classification_report, r2_score

# target_col = '{target}'
# feature_cols = [c for c in df_clean.columns if c != target_col]

# # Encode categoricals
# df_ml = df_clean[feature_cols + [target_col]].copy()
# for col in df_ml.select_dtypes(include='object').columns:
#     df_ml[col] = LabelEncoder().fit_transform(df_ml[col].astype(str))

# # Impute
# imputer = SimpleImputer(strategy='median')
# X = pd.DataFrame(imputer.fit_transform(df_ml[feature_cols]), columns=feature_cols)
# y = df_ml[target_col]

# # Split & train
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Auto-detect problem type
# is_classification = (y.dtype == 'object' or y.nunique() <= 20)
# model = RandomForestClassifier(n_estimators=100, random_state=42) if is_classification else RandomForestRegressor(n_estimators=100, random_state=42)
# model.fit(X_train, y_train)

# y_pred = model.predict(X_test)
# if is_classification:
#     print(f"Accuracy: {{accuracy_score(y_test, y_pred):.4f}}")
#     print(classification_report(y_test, y_pred))
# else:
#     print(f"R² Score: {{r2_score(y_test, y_pred):.4f}}")

# # Feature importance
# fi = pd.Series(model.feature_importances_, index=feature_cols).sort_values(ascending=False).head(15)
# fig = px.bar(x=fi.values, y=fi.index, orientation='h', title='Feature Importance')
# fig.update_layout(yaxis={'autorange': 'reversed'})
# fig.show()"""))

#     # ── Section 7: Export ─────────────────────────────────────────────────────
#     cells.append(_make_cell("markdown", "## 7. Export Results"))
#     cells.append(_make_cell("code", """# Export cleaned dataset
# df_clean.to_csv('datapilot_cleaned_data.csv', index=False)
# print(f"✅ Cleaned data saved: datapilot_cleaned_data.csv ({df_clean.shape[0]:,} rows)")

# # Summary statistics
# df_clean.describe().to_excel('datapilot_stats_summary.xlsx')
# print("✅ Stats saved: datapilot_stats_summary.xlsx")"""))

#     # Build notebook JSON
#     notebook = {
#         "nbformat": 4,
#         "nbformat_minor": 5,
#         "metadata": {
#             "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
#             "language_info": {"name": "python", "version": "3.10.0"},
#             "datapilot": {
#                 "generated": ts,
#                 "source_file": file_name,
#                 "version": "2.0",
#             },
#         },
#         "cells": cells,
#     }
#     return json.dumps(notebook, indent=2, ensure_ascii=False)
 
