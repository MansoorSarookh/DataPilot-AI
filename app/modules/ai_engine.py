"""
DataPilot AI â€” AI Engine
Integrates Groq LLM for conversational data analysis with fallback to rule-based heuristics.
"""

import streamlit as st
import pandas as pd
import numpy as np
import json
import re

# â”€â”€ Groq client initialization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_groq_client():
    """Initialize Groq client with API key from Streamlit secrets."""
    try:
        from groq import Groq
        api_key = st.secrets.get("GROQ_API_KEY", "")
        if api_key:
            return Groq(api_key=api_key)
    except Exception:
        pass
    return None


# â”€â”€ Context builder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_dataset_context(df: pd.DataFrame, max_rows: int = 5) -> dict:
    """Build a structured dataset context dict for LLM prompts."""
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
    cat_cols = df.select_dtypes(include="object").columns.tolist()
    datetime_cols = df.select_dtypes(include="datetime").columns.tolist()

    stats = {}
    for col in numeric_cols[:10]:
        stats[col] = {
            "mean": round(float(df[col].mean()), 3),
            "std": round(float(df[col].std()), 3),
            "min": round(float(df[col].min()), 3),
            "max": round(float(df[col].max()), 3),
            "nulls": int(df[col].isna().sum()),
        }

    return {
        "shape": {"rows": len(df), "cols": len(df.columns)},
        "columns": df.columns.tolist(),
        "numeric_columns": numeric_cols,
        "categorical_columns": cat_cols,
        "datetime_columns": datetime_cols,
        "null_counts": df.isna().sum().to_dict(),
        "numeric_stats": stats,
        "sample": df.head(max_rows).to_dict(orient="records"),
        "dtypes": df.dtypes.astype(str).to_dict(),
        "duplicates": int(df.duplicated().sum()),
    }


def build_system_prompt() -> str:
    return """You are DataPilot, an expert AI data scientist assistant. Your role is to:
1. Analyze datasets and provide concise, numbered insights backed by actual numbers from the data.
2. Suggest actionable next steps (cleaning, feature engineering, model selection).
3. Identify data quality issues, bias, and ML suitability.
4. Recommend appropriate statistical tests and visualizations.
5. Be direct and professional. NEVER make up numbers â€” only cite figures from the dataset context provided.

Format responses with:
- ğŸ“Š **Insight:** <main finding>
- âš ï¸ **Risk:** <any data quality concern>
- âœ… **Action:** <recommended next step>

Keep responses under 300 words unless specifically asked for detail."""


def build_user_prompt(question: str, context: dict, chat_history: list) -> str:
    """Construct the full prompt with dataset context + history."""
    history_text = ""
    for msg in chat_history[-4:]:  # last 4 messages for context window management
        role = "User" if msg["role"] == "user" else "DataPilot"
        history_text += f"{role}: {msg['content']}\n"

    ctx_json = json.dumps(context, default=str, indent=2)
    return f"""Dataset Context:
{ctx_json}

Previous conversation:
{history_text}

User Question: {question}

Provide a data-driven, concise response."""


# â”€â”€ Main chat function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def chat_with_data(
    question: str,
    df: pd.DataFrame,
    chat_history: list,
    model: str = "llama-3.3-70b-versatile",
) -> str:
    """
    Send a question about the dataset to Groq LLM.
    Falls back to rule-based heuristics if API is unavailable.
    """
    client = get_groq_client()
    context = build_dataset_context(df)

    if client:
        try:
            user_prompt = build_user_prompt(question, context, chat_history)
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": build_system_prompt()},
                    {"role": "user", "content": user_prompt},
                ],
                max_tokens=600,
                temperature=0.4,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"âš ï¸ AI API error: {e}\n\n" + _fallback_response(question, df, context)
    else:
        return _fallback_response(question, df, context)


# â”€â”€ Narrative insight generator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_chart_narrative(
    chart_type: str,
    column: str,
    df: pd.DataFrame,
    secondary_column: str = None,
) -> str:
    """
    Generate an AI narrative for a given chart. Uses LLM if available,
    otherwise uses rule-based templates.
    """
    client = get_groq_client()
    context = build_dataset_context(df)

    if client:
        prompt = f"""I just created a {chart_type} chart for the column '{column}'{f" vs '{secondary_column}'" if secondary_column else ""}.

Dataset context: {json.dumps(context, default=str)}

Generate a short chart narrative (max 100 words) with:
- ğŸ“Š Explanation of what the chart shows
- ğŸ“ˆ Key insight or finding  
- âš ï¸ Any risk or warning
- âœ… Suggested action"""
        try:
            resp = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[
                    {"role": "system", "content": build_system_prompt()},
                    {"role": "user", "content": prompt},
                ],
                max_tokens=200,
                temperature=0.3,
            )
            return resp.choices[0].message.content.strip()
        except Exception:
            pass

    return _template_narrative(chart_type, column, df, secondary_column)


def generate_executive_summary(df: pd.DataFrame, trust_score: dict, insights: list) -> str:
    """Generate an AI executive summary for the report."""
    client = get_groq_client()
    context = build_dataset_context(df)

    if client:
        prompt = f"""Generate a professional executive summary (200 words max) for a data analysis report.

Dataset: {context['shape']['rows']} rows Ã— {context['shape']['cols']} columns
Trust Score: {trust_score.get('overall', 0):.0%}
Key Flags: {trust_score.get('flags', [])}
Top Insights: {insights[:5]}

Include: dataset overview, quality assessment, key findings, and recommendations."""
        try:
            resp = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[
                    {"role": "system", "content": "You are a senior data analyst writing executive reports."},
                    {"role": "user", "content": prompt},
                ],
                max_tokens=350,
                temperature=0.3,
            )
            return resp.choices[0].message.content.strip()
        except Exception:
            pass

    return _fallback_executive_summary(df, trust_score)


# â”€â”€ Fallback heuristics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _fallback_response(question: str, df: pd.DataFrame, context: dict) -> str:
    """Rule-based fallback when Groq API is unavailable."""
    q = question.lower()
    rows, cols = context["shape"]["rows"], context["shape"]["cols"]
    numeric_cols = context["numeric_columns"]
    null_counts = context["null_counts"]
    
    total_nulls = sum(null_counts.values())
    null_pct = total_nulls / (rows * cols) * 100 if rows * cols > 0 else 0

    if any(w in q for w in ["reliable", "trust", "quality", "good"]):
        return (
            f"ğŸ“Š **Dataset Quality Assessment**\n\n"
            f"Your dataset has **{rows:,} rows** and **{cols} columns**.\n\n"
            f"- Missing values: **{null_pct:.1f}%** of all cells\n"
            f"- Duplicate rows: **{context.get('duplicates', 0)}**\n"
            f"- Numeric columns: **{len(numeric_cols)}**\n\n"
            f"{'âš ï¸ **Risk:** High missing data may affect analysis.' if null_pct > 10 else 'âœ… Missing data is within acceptable range.'}\n\n"
            f"âœ… **Action:** Review columns with high missing rates before modeling."
        )
    elif any(w in q for w in ["trend", "pattern", "insight", "tell"]):
        if numeric_cols:
            col = numeric_cols[0]
            try:
                series = df[col].dropna()
                trend = "increasing" if series.iloc[-1] > series.iloc[0] else "decreasing"
                return (
                    f"ğŸ“Š **Key Patterns Detected**\n\n"
                    f"- Column **'{col}'**: {trend} trend (first={series.iloc[0]:.2f} â†’ last={series.iloc[-1]:.2f})\n"
                    f"- Mean: **{series.mean():.3f}**, Std: **{series.std():.3f}**\n\n"
                    f"âœ… **Action:** Explore correlation heatmap to discover inter-variable relationships."
                )
            except Exception:
                pass
        return f"ğŸ“Š Dataset has {cols} columns. Go to the **Analyze** tab for visualizations and trends."
    elif any(w in q for w in ["column", "feature", "important", "matter"]):
        return (
            f"ğŸ“Š **Feature Overview**\n\n"
            f"- **{len(numeric_cols)} numeric** columns available for modeling.\n"
            f"- **{len(context['categorical_columns'])} categorical** columns (may need encoding).\n\n"
            f"âš ï¸ **Risk:** High-cardinality categorical features can cause overfitting.\n\n"
            f"âœ… **Action:** Use the **ML Studio** tab to get auto feature importance after training."
        )
    elif any(w in q for w in ["ml", "model", "predict", "machine"]):
        return (
            f"ğŸ¯ **ML Readiness**\n\n"
            f"- Dataset: **{rows:,} rows** ({"âœ… sufficient" if rows > 200 else "âš ï¸ may be too small"} for ML)\n"
            f"- Features: **{len(numeric_cols)}** numeric columns available\n\n"
            f"âœ… **Action:** Go to **ML Studio** â†’ select your target column â†’ run Auto-ML."
        )
    else:
        return (
            f"ğŸ“Š **Dataset Summary**\n\n"
            f"- Shape: **{rows:,} rows Ã— {cols} columns**\n"
            f"- Numeric features: **{len(numeric_cols)}**\n"
            f"- Missing data: **{null_pct:.1f}%**\n\n"
            f"Try asking: *'What trends exist?'*, *'Is this dataset reliable?'*, or *'Prepare ML-ready data'*"
        )


def _template_narrative(chart_type: str, column: str, df: pd.DataFrame, secondary: str = None) -> str:
    """Template-based chart narrative."""
    try:
        if column in df.select_dtypes(include=np.number).columns:
            series = df[column].dropna()
            mean_val = series.mean()
            std_val = series.std()
            skew = series.skew()
            skew_dir = "right-skewed" if skew > 0.5 else "left-skewed" if skew < -0.5 else "approximately normal"
            outliers = len(series[(series - mean_val).abs() > 3 * std_val])
            return (
                f"ğŸ“Š **{chart_type} â€” {column}**\n\n"
                f"Distribution is **{skew_dir}** (skewness={skew:.2f}). "
                f"Mean = {mean_val:.3f}, Std = {std_val:.3f}.\n\n"
                f"{'âš ï¸ **Risk:** ' + str(outliers) + ' potential outliers detected (>3Ïƒ).' if outliers > 0 else 'âœ… No significant outliers detected.'}\n\n"
                f"âœ… **Action:** {'Consider log transformation to normalize distribution.' if abs(skew) > 1 else 'Distribution is suitable for parametric analysis.'}"
            )
    except Exception:
        pass
    return f"ğŸ“Š **{chart_type}** visualization for **{column}**."


def _fallback_executive_summary(df: pd.DataFrame, trust_score: dict) -> str:
    rows, cols = df.shape
    score = trust_score.get("overall", 0)
    label = "ğŸŸ¢ Reliable" if score > 0.80 else "ğŸŸ¡ Needs Review" if score > 0.60 else "ğŸ”´ High Risk"
    return (
        f"**Executive Summary â€” DataPilot AI Analysis**\n\n"
        f"Dataset contains {rows:,} records across {cols} variables. "
        f"Overall data quality is rated **{label}** with a trust score of **{score:.0%}**. "
        f"Key focus areas include addressing missing values, validating data types, "
        f"and reviewing class balance before proceeding with machine learning workflows.\n\n"
        f"Recommendation: Complete the data cleaning pipeline in the Clean tab and "
        f"validate the dataset using the Statistical Intelligence Engine before modeling."
    )
 
